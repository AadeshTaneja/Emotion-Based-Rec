# -*- coding: utf-8 -*-
"""Train_Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WLi9CDIskLYDAtxZFv8aMnox-r4Q--o1
"""

dataset_path = "datasets/fer2013"  # Path to store the FER2013 dataset

if not os.path.exists(dataset_path):
    print("Downloading FER2013 dataset...")
    path = kagglehub.dataset_download("msambare/fer2013")
    print("Downloaded dataset to:", path)  # Print path to check it
else:
    print("Dataset already exists at:", dataset_path)

import os
import kagglehub
import zipfile
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout


print("Downloading FER2013 dataset...")
dataset_path = kagglehub.dataset_download("msambare/fer2013")
print("Dataset downloaded to:", dataset_path)

for file in os.listdir(dataset_path):
    if file.endswith('.zip'):
        print(f"Extracting {file}...")
        with zipfile.ZipFile(os.path.join(dataset_path, file), 'r') as zip_ref:
            zip_ref.extractall(dataset_path)

train_dir = os.path.join(dataset_path, 'train')
test_dir = os.path.join(dataset_path, 'test')


if not os.path.exists(train_dir) or not os.path.exists(test_dir):
    raise FileNotFoundError("Train and test directories not found in extracted dataset.")

#ImageDataGenerator for loading and preprocessing images
# Image data generator with augmentation for training
train_datagen = ImageDataGenerator(
    rescale=1./255,           # Normalize pixel values
    rotation_range=10,
    width_shift_range=0.1,
    height_shift_range=0.1,
    horizontal_flip=True
)

# Simple rescaling for validation/testing
test_datagen = ImageDataGenerator(rescale=1./255)

# Create training and validation generators
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(48, 48),
    color_mode='grayscale',
    batch_size=64,
    class_mode='categorical'
)

validation_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(48, 48),
    color_mode='grayscale',
    batch_size=64,
    class_mode='categorical'
)

#Define the CNN model architecture
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)),
    MaxPooling2D((2, 2)),
    Dropout(0.25),

    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Dropout(0.25),

    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Dropout(0.25),

    Flatten(),
    Dense(256, activation='relu'),
    Dropout(0.5),
    Dense(train_generator.num_classes, activation='softmax')  # Number of output classes based on folder structure
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

#Train the Model with the Data Generators
epochs = 50

history = model.fit(
    train_generator,
    validation_data=validation_generator,
    epochs=epochs,
    verbose=1
)

#Save the model after training
model.save('emotion_detection_model.h5')
print("Model saved as emotion_detection_model.h5")

#Evaluate the model
loss, accuracy = model.evaluate(validation_generator, verbose=0)
print(f"Validation Accuracy: {accuracy:.2f}")